{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c33020",
   "metadata": {},
   "source": [
    "> Фиксим баги в коде коллеги\n",
    "Скачайте ноутбук и запустите все ячейки (в Подсказках есть инструкция, как открыть скаченный ноутбук в JupyterHub). Этот ноутбук приближен к тому, с чем вы столкнетесь в реальности: разбросанные эксперименты в разных частях, не очень большая документация. Не волнуйтесь, мы с вами не будем продолжать эти традиции и будем писать хорошие ноутбуки :)\n",
    "\n",
    "В самом конце вы должны увидеть распечатку переменной credit_payments. Результат вывода второй ячейки будет:\n",
    "\n",
    "0.03091597557067871\n",
    "\n",
    "1671.9166620000015\n",
    "\n",
    "\n",
    "Ваш тех.директор сказал, что в коде ошибка - там надо убрать строку credit_payments.append(5), потому что она осталась от эксперимента. Вы с радостью это делаете на глазах у шефа, и хотите перезапустить ячейку с циклом.\n",
    "\n",
    "Подумайте, какой результат ожидаете получить, а затем перезапустите ячейку с циклом for. Что получилось на выходе?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66d23d",
   "metadata": {},
   "source": [
    "3338.83\n",
    "\n",
    "Верно! Попробуйте перезапустить ядро, прогнать ноутбук от начала до конца, затем убрать .append(5) и еще раз запустить последнюю ячейку. Вы получите примерно удвоенное значение от изначального."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b9e8db",
   "metadata": {},
   "source": [
    "> Пишем воспроизводимый код\n",
    "Что можно сделать, чтобы после перезапуска последней ячейки всегда получился одинаковый результат?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b23a4",
   "metadata": {},
   "source": [
    "Перенести credit_payments = [] в ячейку с циклом for\n",
    "\n",
    "Стоит перенести объявление credit_payments = [] в ту ячейку, где происходит массовый .append() - это ячейка с циклом for. Просто удалить объявление не поможет - Jupyter никогда автоматически не создает переменные за вас. Писать credit_payments = credit_payments.append(...) не имеет смысла, так как .append() ничего не возвращает и меняет массив на месте (т.е. не создавая копию)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e49bef",
   "metadata": {},
   "source": [
    "> Строим графики\n",
    "\n",
    "Откройте ноутбук по ссылке. Посмотрите на графики, потом попробуйте их воссоздать. Как добиться того, чтобы при \"Restart Kernel and run all\" получались схожие графики? \n",
    "\n",
    "NB! На данном этапе не требуется подробно вникать в код ноутбука, данные темы будут рассмотрены позже. Сейчас вам достаточно понять идею и запустить готовый код. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aae5d5",
   "metadata": {},
   "source": [
    "Вернуть импорт matplotlib.pyplot в первую ячейку, где уже используется отрисовка графиков\n",
    "\n",
    "Лучше всего делать ноутбуки так, чтобы всегда можно было запустить все ячейки от начала до конца. Для этого в примере надо перенести import matplotlib.pyplot в первую ячейку кода."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85259a",
   "metadata": {},
   "source": [
    " Применяем магические команды jupyter\n",
    "Реализуйте скалярное произведение двух векторов размера 1e5 через цикл for в ноутбуке и замерьте скорость выполнения кода с использованием магической команды %%timeit. Используйте для быстрой генерации вектора такой трюк: vec1 = list(range(int(1e5))).\n",
    "\n",
    "Рекомендуем скалярное произведение обернуть в функцию.\n",
    "\n",
    "Сколько секунд отрабатывала ваша функция?\n",
    "\n",
    "NB! Убедитесь, что замеряете только время выполнения скалярного произведения и ничего больше.\n",
    "\n",
    "\n",
    "> Результат \"магического\" умножения\n",
    "Какой порядок (т.е. число после e+...) имеет результат скалярного произведения двух векторов из предыдущего степа?\n",
    "\n",
    "Hint: для выполнения этого задания почитайте про формат scientific notation в питоне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4688bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.35 ms ± 106 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "333328333350000\n",
      "3.333283e+14\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 1: Определяем функцию и создаём векторы\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def dot_product_loop(vec1, vec2):\n",
    "    \"\"\"Вычисляет скалярное произведение через цикл for.\"\"\"\n",
    "    result = 0\n",
    "    for i in range(len(vec1)):\n",
    "        result += vec1[i] * vec2[i]\n",
    "    return result\n",
    "\n",
    "# Создаем векторы размером 1e5 (100 000 элементов)\n",
    "vec1 = list(range(int(1e5)))\n",
    "vec2 = list(range(int(1e5)))\n",
    "\n",
    "# Ячейка 2: Замеряем скорость выполнения функции\n",
    "\n",
    "%timeit dot_product_loop(vec1, vec2)\n",
    "\n",
    "scalar_result = dot_product_loop(vec1, vec2)\n",
    "\n",
    "# Печатаем результат, чтобы увидеть его в научной нотации\n",
    "print(scalar_result)\n",
    "# Дополнительная ячейка для форматирования\n",
    "print(f\"{scalar_result:e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21363045",
   "metadata": {},
   "source": [
    "> Предобработка данных: нормализация признаков\n",
    "Вы готовите данные для машинного обучения. У вас есть признаки в разных масштабах:\n",
    "\n",
    "Возраст пользователя (18-65 лет);\n",
    "\n",
    "Доход (50,000-500,000 рублей);\n",
    "\n",
    "Количество покупок (0-100).\n",
    "\n",
    "Проблема в том, что алгоритмы машинного обучения чувствительны к масштабу признаков. Признак с большими значениями (доход) будет доминировать над признаком с маленькими значениями (возраст), даже если они одинаково важны для предсказания.\n",
    "\n",
    "Задача\n",
    "Реализуйте функцию нормализации, которая приводит все признаки к диапазону [0,1], сохраняя их относительные пропорции.\n",
    "\n",
    "def normalize(X: np.ndarray) -> np.ndarray:\n",
    "    ...\n",
    "\n",
    "\n",
    "Почему нормализация важна?\n",
    "\n",
    "Нормализация делает все признаки одинаково важными для алгоритма, независимо от их исходного масштаба. Это особенно важно для алгоритмов, основанных на расстояниях (k-NN, SVM) или градиентном спуске.\n",
    "\n",
    "Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036bafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def normalize(X: np.ndarray) -> np.ndarray:\n",
    "    X_min = X.min(axis=0,keepdims=True)\n",
    "    X_max = X.max(axis=0,keepdims=True)\n",
    "    ans = (X - X_min)/(X_max - X_min)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f4e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# До нормализации\n",
    "age = [25, 30, 35]        # 0-100 масштаб\n",
    "income = [50000, 100000, 150000]  # 0-1000000 масштаб\n",
    "\n",
    "# После нормализации\n",
    "age_norm = [0.0, 0.5, 1.0]        # 0-1 масштаб\n",
    "income_norm = [0.0, 0.5, 1.0]     # 0-1 масштаб\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97bee3b",
   "metadata": {},
   "source": [
    "> Поиск похожих объектов по эмбеддингам\n",
    "Вы работаете ML-инженером в продуктовой команде, которая реализует поиск по смыслу. Например:\n",
    "\n",
    "Рекомендации похожих товаров,\n",
    "\n",
    "Поиск новостей, близких по смыслу,\n",
    "\n",
    "Определение ближайших пользователей по поведенческим паттернам,\n",
    "\n",
    "Сравнение эмбеддингов изображений, текстов или пользователей.\n",
    "\n",
    "Каждому объекту (товару, тексту, пользователю) соответствует вектор признаков — эмбеддинг, полученный из ML-модели. Эти векторы уже сохранены в массиве X, где каждая строка — это вектор одного объекта.\n",
    "\n",
    "Пользователь выбрал объект с эмбеддингом v. Нужно найти, насколько каждый вектор из X близок к нему по смыслу.\n",
    "\n",
    "Задача\n",
    "Реализуйте функцию, которая для заданного массива векторов X (размера n×d) и одного вектора v (d, эмбеддинг запроса или выбранного объекта), вычисляет косинусное сходство между v и каждым вектором из X.\n",
    "\n",
    "Возвращаемое значение — массив длиной n, где каждый элемент показывает степень близости между v и соответствующей строкой из X.\n",
    "\n",
    "def cosine_similarity(X: np.ndarray, v: np.ndarray) -> np.ndarray:\n",
    "    ...\n",
    "\n",
    "\n",
    "Почему именно косинусное сходство?\n",
    "\n",
    "Косинусное сходство показывает угол между векторами и хорошо работает при сравнении эмбеддингов — оно не зависит от длины вектора и позволяет находить наиболее похожие объекты по направлению (смыслу), а не масштабу.\n",
    "\n",
    "Пример использования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine_similarity(X: np.ndarray, v: np.ndarray) -> np.ndarray:\n",
    "    ans = np.dot(X,(v.T))/(np.linalg.norm(X,axis=1)*np.linalg.norm(v))\n",
    "    return ans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4be5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 0],    # объект A\n",
    "    [0, 1],    # объект B\n",
    "    [1, 1],    # объект C\n",
    "])\n",
    "\n",
    "v = np.array([1, 0])  # эмбеддинг запроса\n",
    "\n",
    "similarities = cosine_similarity(X, v)\n",
    "print(similarities)  # [1.0, 0.0, 0.707...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ae7b5",
   "metadata": {},
   "source": [
    "> Анализ данных: обнаружение аномалий\n",
    "Вы анализируете данные для выявления аномальных значений, которые могут указывать на:\n",
    "\n",
    "Ошибки в сборе данных,\n",
    "\n",
    "Мошеннические транзакции,\n",
    "\n",
    "Технические сбои в системе,\n",
    "\n",
    "Редкие, но важные события.\n",
    "\n",
    "Для этого используется статистический метод — правило 1.5 IQR (межквартильного размаха), которое является стандартным подходом в анализе данных.\n",
    "\n",
    "Задача\n",
    "Реализуйте функцию для обнаружения выбросов в одномерном массиве данных по правилу 1.5 IQR.\n",
    "\n",
    "Правило 1.5 IQR:\n",
    "\n",
    "Q1 (первый квартиль) — 25-й процентиль\n",
    "\n",
    "Q3 (третий квартиль) — 75-й процентиль\n",
    "\n",
    "IQR (межквартильный размах) = Q3 - Q1\n",
    "\n",
    "Нижняя граница = Q1 - 1.5 × IQR\n",
    "\n",
    "Верхняя граница = Q3 + 1.5 × IQR\n",
    "\n",
    "Выбросы — значения вне диапазона [нижняя граница, верхняя граница].\n",
    "\n",
    "def detect_outliers(x: np.ndarray) -> np.ndarray:\n",
    "    ...\n",
    "\n",
    "\n",
    "Пример использования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ec51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def detect_outliers(x: np.ndarray) -> np.ndarray:\n",
    "    q1 = np.percentile(x, 25)\n",
    "    q3 = np.percentile(x, 75)\n",
    "    low = q1 - 1.5*(q3-q1)\n",
    "    high = q3 + 1.5*(q3-q1)\n",
    "    ans = ((x > high) | (x < low))\n",
    "    # ans = x > q3 | x <q1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd99ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 3, 4, 100, 6, 7, 8, 9]  # 100 - явный выброс\n",
    "outliers = detect_outliers(data)\n",
    "print(outliers)  # [False, False, False, False, True, False, False, False, False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04b5c6",
   "metadata": {},
   "source": [
    "![Компьютер](img/4-1.png)\n",
    "![Компьютер](img/4-2.png)\n",
    "![Компьютер](img/4-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def ridge_inverse(X: np.ndarray, lambda_: float) -> np.ndarray:\n",
    "    inv_x = np.linalg.inv(X.T @ X + lambda_ * np.eye(X.shape[1]))\n",
    "    return inv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6288244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6]])  # признаки объектов\n",
    "lambda_ = 0.1  # сила регуляризации\n",
    "inv_matrix = ridge_inverse(X, lambda_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3370d0",
   "metadata": {},
   "source": [
    "> Предобработка данных для модели машинного обучения\n",
    "Вы готовите данные для обучения модели. В числовых признаках есть пропуски (np.nan), которые модель не может обрабатывать напрямую.\n",
    "\n",
    "Задача\n",
    "\n",
    "Заполните пропуски медианой по каждому признаку (столбцу), чтобы сохранить распределение значений и не вносить смещения, как это бывает при замене средним. Для простоты считайте, что как минимум один элемент будет не nan.\n",
    "\n",
    "def fill_na_with_median(X: np.ndarray) -> np.ndarray:\n",
    "    ...\n",
    "\n",
    "\n",
    "Почему именно медиана?\n",
    "\n",
    "Медиана устойчива к выбросам и лучше сохраняет центральную тенденцию данных. При замене пропусков средним значением один экстремальный выброс может сильно исказить результат.\n",
    "\n",
    "Требования:\n",
    "\n",
    "Не изменять исходную матрицу;\n",
    "\n",
    "Заполнять пропуски медианой по каждому столбцу отдельно;\n",
    "\n",
    "Возвращать новую матрицу без пропусков.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def fill_na_with_median(X: np.ndarray) -> np.ndarray:\n",
    "    X = np.where(np.isnan(X), np.nanmedian(X, axis=0),X)\n",
    "    return X\n",
    "\n",
    "# A = np.array([\n",
    "#     [1,   2,   np.nan],\n",
    "#     [4,   np.nan, 6],\n",
    "#     [np.nan,   8,   9]\n",
    "# ])\n",
    "\n",
    "# print(fill_na_with_median(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d538a34",
   "metadata": {},
   "source": [
    "> Предобработка данных: кодирование категориальных признаков\n",
    "Вы работаете с данными пользователей интернет-магазина. У вас есть категориальные признаки:\n",
    "\n",
    "Город проживания: [\"Москва\", \"СПб\", \"Казань\", \"Москва\", \"Екатеринбург\"]\n",
    "\n",
    "Категория товара: [\"электроника\", \"одежда\", \"книги\", \"электроника\"]\n",
    "\n",
    "Уровень дохода: [\"низкий\", \"средний\", \"высокий\", \"средний\"]\n",
    "\n",
    "Проблема в том, что алгоритмы машинного обучения работают только с числами, а не с текстом. Нужно преобразовать категории в числовой формат.\n",
    "\n",
    "В этом задании запрещено использовать OHE из sklearn.\n",
    "\n",
    "Задача\n",
    "Реализуйте функцию one-hot encoding, которая преобразует категориальные данные в числовой формат для машинного обучения.\n",
    "\n",
    "def one_hot_encode(categories: np.ndarray) -> tuple[np.ndarray, list[str]]:\n",
    "    ...\n",
    "\n",
    "\n",
    "Почему one-hot encoding?\n",
    "\n",
    "Этот метод создает отдельный бинарный признак для каждой категории. Например, для городов:\n",
    "\n",
    "Москва → [1,0,0,0]\n",
    "\n",
    "СПб → [0,1,0,0]\n",
    "\n",
    "Казань → [0,0,1,0]\n",
    "\n",
    "Екатеринбург → [0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def one_hot_encode(categories: np.ndarray) -> tuple[np.ndarray, list[str]]:\n",
    "    unique_categories = np.unique(categories)\n",
    "    seen = { }\n",
    "    count = 0\n",
    "    A = np.array([])\n",
    "    for i in unique_categories:\n",
    "        if i not in seen:\n",
    "            seen[i] = count\n",
    "            count +=1\n",
    "        print(seen)\n",
    "    for i in categories:\n",
    "        row = np.zeros(len(unique_categories))\n",
    "        row[seen[i]] = 1\n",
    "        if A.size == 0:\n",
    "            A = row\n",
    "        else:\n",
    "            A = np.vstack([A, row])\n",
    "    return A, unique_categories.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# cities = [\"РњРѕСЃРєРІР°\", \"РЎРџР±\", \"РњРѕСЃРєРІР°\", \"РљР°Р·Р°РЅСЊ\"]\n",
    "# one_hot_encode(cities)\n",
    "    # retrun ,unique_categories.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\"Москва\", \"СПб\", \"Москва\", \"Казань\"]\n",
    "one_hot_matrix, unique_cities = one_hot_encode(cities)\n",
    "print(unique_cities)  # [\"Казань\", \"Москва\", \"СПб\"] (отсортировано)\n",
    "print(one_hot_matrix)\n",
    "# [[0, 1, 0],  # Москва\n",
    "#  [0, 0, 1],  # СПб  \n",
    "#  [0, 1, 0],  # Москва\n",
    "#  [1, 0, 0]]  # Казань\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
